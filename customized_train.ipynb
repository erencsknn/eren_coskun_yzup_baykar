{"cells":[{"cell_type":"markdown","metadata":{"id":"QS8YHrEhbpas"},"source":["## Install MMSegmentation\n","\n","This step may take several minutes.\n","\n","We use PyTorch 1.12 and CUDA 11.3 for this tutorial. You may install other versions by change the version number in pip install command.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717008225471,"user":{"displayName":"eren coşkun","userId":"10852037997743920338"},"user_tz":-180},"id":"UWyLrLYaNEaL","outputId":"d767241e-aeeb-43ef-e0df-7102f31c611c"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Mar_28_02:30:10_Pacific_Daylight_Time_2024\n","Cuda compilation tools, release 12.4, V12.4.131\n","Build cuda_12.4.r12.4/compiler.34097967_0\n","gcc (MinGW.org GCC-6.3.0-1) 6.3.0\n","Copyright (C) 2016 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"]}],"source":["# Check nvcc version\n","!nvcc -V\n","# Check GCC version\n","!gcc --version"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1480,"status":"ok","timestamp":1717008279792,"user":{"displayName":"eren coşkun","userId":"10852037997743920338"},"user_tz":-180},"id":"mAE_h7XhPT7d","outputId":"b10f0473-db9c-4e0f-e1a1-a8fd5b1ee7cb"},"outputs":[{"name":"stderr","output_type":"stream","text":["f:\\anaconda3\\envs\\finish_project_baykar\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["1.12.0 True\n","1.2.2\n"]}],"source":["# Check Pytorch installation\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","\n","# Check MMSegmentation installation\n","import mmseg\n","print(mmseg.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":429,"status":"ok","timestamp":1717006323078,"user":{"displayName":"eren coşkun","userId":"10852037997743920338"},"user_tz":-180},"id":"oXfxD6bBWzEp","outputId":"25230d6e-40eb-4dda-85d2-90a9e414f23d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Config:\n","crop_size = (\n","    512,\n","    1024,\n",")\n","data_preprocessor = dict(\n","    bgr_to_rgb=True,\n","    mean=[\n","        123.675,\n","        116.28,\n","        103.53,\n","    ],\n","    pad_val=0,\n","    seg_pad_val=255,\n","    size=(\n","        512,\n","        1024,\n","    ),\n","    std=[\n","        58.395,\n","        57.12,\n","        57.375,\n","    ],\n","    type='SegDataPreProcessor')\n","data_root = 'data/cityscapes/'\n","dataset_type = 'CityscapesDataset'\n","default_hooks = dict(\n","    checkpoint=dict(by_epoch=False, interval=4000, type='CheckpointHook'),\n","    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n","    param_scheduler=dict(type='ParamSchedulerHook'),\n","    sampler_seed=dict(type='DistSamplerSeedHook'),\n","    timer=dict(type='IterTimerHook'),\n","    visualization=dict(type='SegVisualizationHook'))\n","default_scope = 'mmseg'\n","env_cfg = dict(\n","    cudnn_benchmark=True,\n","    dist_cfg=dict(backend='nccl'),\n","    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n","img_ratios = [\n","    0.5,\n","    0.75,\n","    1.0,\n","    1.25,\n","    1.5,\n","    1.75,\n","]\n","load_from = None\n","log_level = 'INFO'\n","log_processor = dict(by_epoch=False)\n","model = dict(\n","    auxiliary_head=dict(\n","        align_corners=False,\n","        channels=256,\n","        concat_input=False,\n","        dropout_ratio=0.1,\n","        in_channels=1024,\n","        in_index=2,\n","        loss_decode=dict(\n","            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n","        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n","        num_classes=19,\n","        num_convs=1,\n","        type='FCNHead'),\n","    backbone=dict(\n","        contract_dilation=True,\n","        depth=50,\n","        dilations=(\n","            1,\n","            1,\n","            2,\n","            4,\n","        ),\n","        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n","        norm_eval=False,\n","        num_stages=4,\n","        out_indices=(\n","            0,\n","            1,\n","            2,\n","            3,\n","        ),\n","        strides=(\n","            1,\n","            2,\n","            1,\n","            1,\n","        ),\n","        style='pytorch',\n","        type='ResNetV1c'),\n","    data_preprocessor=dict(\n","        bgr_to_rgb=True,\n","        mean=[\n","            123.675,\n","            116.28,\n","            103.53,\n","        ],\n","        pad_val=0,\n","        seg_pad_val=255,\n","        size=(\n","            512,\n","            1024,\n","        ),\n","        std=[\n","            58.395,\n","            57.12,\n","            57.375,\n","        ],\n","        type='SegDataPreProcessor'),\n","    decode_head=dict(\n","        align_corners=False,\n","        channels=512,\n","        dropout_ratio=0.1,\n","        in_channels=2048,\n","        in_index=3,\n","        loss_decode=dict(\n","            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n","        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n","        num_classes=19,\n","        pool_scales=(\n","            1,\n","            2,\n","            3,\n","            6,\n","        ),\n","        type='PSPHead'),\n","    pretrained='open-mmlab://resnet50_v1c',\n","    test_cfg=dict(mode='whole'),\n","    train_cfg=dict(),\n","    type='EncoderDecoder')\n","norm_cfg = dict(requires_grad=True, type='SyncBN')\n","optim_wrapper = dict(\n","    clip_grad=None,\n","    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n","    type='OptimWrapper')\n","optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n","param_scheduler = [\n","    dict(\n","        begin=0,\n","        by_epoch=False,\n","        end=40000,\n","        eta_min=0.0001,\n","        power=0.9,\n","        type='PolyLR'),\n","]\n","resume = False\n","test_cfg = dict(type='TestLoop')\n","test_dataloader = dict(\n","    batch_size=1,\n","    dataset=dict(\n","        data_prefix=dict(\n","            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n","        data_root='data/cityscapes/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(keep_ratio=True, scale=(\n","                2048,\n","                1024,\n","            ), type='Resize'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='CityscapesDataset'),\n","    num_workers=4,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=False, type='DefaultSampler'))\n","test_evaluator = dict(\n","    iou_metrics=[\n","        'mIoU',\n","    ], type='IoUMetric')\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(keep_ratio=True, scale=(\n","        2048,\n","        1024,\n","    ), type='Resize'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='PackSegInputs'),\n","]\n","train_cfg = dict(max_iters=40000, type='IterBasedTrainLoop', val_interval=4000)\n","train_dataloader = dict(\n","    batch_size=2,\n","    dataset=dict(\n","        data_prefix=dict(\n","            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),\n","        data_root='data/cityscapes/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations'),\n","            dict(\n","                keep_ratio=True,\n","                ratio_range=(\n","                    0.5,\n","                    2.0,\n","                ),\n","                scale=(\n","                    2048,\n","                    1024,\n","                ),\n","                type='RandomResize'),\n","            dict(\n","                cat_max_ratio=0.75, crop_size=(\n","                    512,\n","                    1024,\n","                ), type='RandomCrop'),\n","            dict(prob=0.5, type='RandomFlip'),\n","            dict(type='PhotoMetricDistortion'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='CityscapesDataset'),\n","    num_workers=2,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=True, type='InfiniteSampler'))\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(\n","        keep_ratio=True,\n","        ratio_range=(\n","            0.5,\n","            2.0,\n","        ),\n","        scale=(\n","            2048,\n","            1024,\n","        ),\n","        type='RandomResize'),\n","    dict(cat_max_ratio=0.75, crop_size=(\n","        512,\n","        1024,\n","    ), type='RandomCrop'),\n","    dict(prob=0.5, type='RandomFlip'),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(type='PackSegInputs'),\n","]\n","tta_model = dict(type='SegTTAModel')\n","tta_pipeline = [\n","    dict(backend_args=None, type='LoadImageFromFile'),\n","    dict(\n","        transforms=[\n","            [\n","                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n","            ],\n","            [\n","                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n","                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n","            ],\n","            [\n","                dict(type='LoadAnnotations'),\n","            ],\n","            [\n","                dict(type='PackSegInputs'),\n","            ],\n","        ],\n","        type='TestTimeAug'),\n","]\n","val_cfg = dict(type='ValLoop')\n","val_dataloader = dict(\n","    batch_size=1,\n","    dataset=dict(\n","        data_prefix=dict(\n","            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n","        data_root='data/cityscapes/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(keep_ratio=True, scale=(\n","                2048,\n","                1024,\n","            ), type='Resize'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='CityscapesDataset'),\n","    num_workers=4,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=False, type='DefaultSampler'))\n","val_evaluator = dict(\n","    iou_metrics=[\n","        'mIoU',\n","    ], type='IoUMetric')\n","vis_backends = [\n","    dict(type='LocalVisBackend'),\n","]\n","visualizer = dict(\n","    name='visualizer',\n","    type='SegLocalVisualizer',\n","    vis_backends=[\n","        dict(type='LocalVisBackend'),\n","    ])\n","\n"]}],"source":["from mmengine import Config\n","cfg = Config.fromfile('configs/pspnet/pspnet_r50-d8_4xb2-40k_cityscapes-512x1024.py')\n","print(f'Config:\\n{cfg.pretty_text}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":425,"status":"ok","timestamp":1717006328989,"user":{"displayName":"eren coşkun","userId":"10852037997743920338"},"user_tz":-180},"id":"eyKnYC1Z7iCV","outputId":"0847f6f4-d4d6-4285-dfbb-a72b0d63227e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Config:\n","crop_size = (\n","    512,\n","    1024,\n",")\n","data_preprocessor = dict(\n","    bgr_to_rgb=True,\n","    mean=[\n","        123.675,\n","        116.28,\n","        103.53,\n","    ],\n","    pad_val=0,\n","    seg_pad_val=255,\n","    size=(\n","        512,\n","        1024,\n","    ),\n","    std=[\n","        58.395,\n","        57.12,\n","        57.375,\n","    ],\n","    type='SegDataPreProcessor')\n","data_root = '/content/mmsegmentation/data/UDD-VDD'\n","dataset_type = 'UDD_VDD_Dataset'\n","default_hooks = dict(\n","    checkpoint=dict(by_epoch=False, interval=500, type='CheckpointHook'),\n","    logger=dict(interval=500, log_metric_by_epoch=False, type='LoggerHook'),\n","    param_scheduler=dict(type='ParamSchedulerHook'),\n","    sampler_seed=dict(type='DistSamplerSeedHook'),\n","    timer=dict(type='IterTimerHook'),\n","    visualization=dict(type='SegVisualizationHook'))\n","default_scope = 'mmseg'\n","env_cfg = dict(\n","    cudnn_benchmark=True,\n","    dist_cfg=dict(backend='nccl'),\n","    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n","img_ratios = [\n","    0.5,\n","    0.75,\n","    1.0,\n","    1.25,\n","    1.5,\n","    1.75,\n","]\n","load_from = '/content/drive/MyDrive/mmsegmentation-colab/mmsegmentation/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n","log_level = 'INFO'\n","log_processor = dict(by_epoch=False)\n","model = dict(\n","    auxiliary_head=dict(\n","        align_corners=False,\n","        channels=256,\n","        concat_input=False,\n","        dropout_ratio=0.1,\n","        in_channels=1024,\n","        in_index=2,\n","        loss_decode=dict(\n","            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n","        norm_cfg=dict(requires_grad=True, type='BN'),\n","        num_classes=7,\n","        num_convs=1,\n","        type='FCNHead'),\n","    backbone=dict(\n","        contract_dilation=True,\n","        depth=50,\n","        dilations=(\n","            1,\n","            1,\n","            2,\n","            4,\n","        ),\n","        norm_cfg=dict(requires_grad=True, type='BN'),\n","        norm_eval=False,\n","        num_stages=4,\n","        out_indices=(\n","            0,\n","            1,\n","            2,\n","            3,\n","        ),\n","        strides=(\n","            1,\n","            2,\n","            1,\n","            1,\n","        ),\n","        style='pytorch',\n","        type='ResNetV1c'),\n","    data_preprocessor=dict(\n","        bgr_to_rgb=True,\n","        mean=[\n","            123.675,\n","            116.28,\n","            103.53,\n","        ],\n","        pad_val=0,\n","        seg_pad_val=255,\n","        size=(\n","            512,\n","            1024,\n","        ),\n","        std=[\n","            58.395,\n","            57.12,\n","            57.375,\n","        ],\n","        type='SegDataPreProcessor'),\n","    decode_head=dict(\n","        align_corners=False,\n","        channels=512,\n","        dropout_ratio=0.1,\n","        in_channels=2048,\n","        in_index=3,\n","        loss_decode=dict(\n","            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n","        norm_cfg=dict(requires_grad=True, type='BN'),\n","        num_classes=7,\n","        pool_scales=(\n","            1,\n","            2,\n","            3,\n","            6,\n","        ),\n","        type='PSPHead'),\n","    pretrained='open-mmlab://resnet50_v1c',\n","    test_cfg=dict(mode='whole'),\n","    train_cfg=dict(),\n","    type='EncoderDecoder')\n","norm_cfg = dict(requires_grad=True, type='BN')\n","optim_wrapper = dict(\n","    clip_grad=None,\n","    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n","    type='OptimWrapper')\n","optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n","param_scheduler = [\n","    dict(\n","        begin=0,\n","        by_epoch=False,\n","        end=40000,\n","        eta_min=0.0001,\n","        power=0.9,\n","        type='PolyLR'),\n","]\n","randomness = dict(seed=0)\n","resume = False\n","test_cfg = dict(type='TestLoop')\n","test_dataloader = dict(\n","    batch_size=1,\n","    dataset=dict(\n","        data_prefix=dict(img_path='val/src', seg_map_path='val/gt'),\n","        data_root='/content/mmsegmentation/data/UDD-VDD',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(keep_ratio=True, scale=(\n","                512,\n","                1024,\n","            ), type='Resize'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='UDD_VDD_Dataset'),\n","    num_workers=4,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=False, type='DefaultSampler'))\n","test_evaluator = dict(\n","    iou_metrics=[\n","        'mIoU',\n","    ], type='IoUMetric')\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(keep_ratio=True, scale=(\n","        512,\n","        1024,\n","    ), type='Resize'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='PackSegInputs'),\n","]\n","train_cfg = dict(max_iters=500, type='IterBasedTrainLoop', val_interval=250)\n","train_dataloader = dict(\n","    batch_size=2,\n","    dataset=dict(\n","        data_prefix=dict(img_path='train/src', seg_map_path='train/gt'),\n","        data_root='/content/mmsegmentation/data/UDD-VDD',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations'),\n","            dict(scale=(\n","                512,\n","                1024,\n","            ), type='Resize'),\n","            dict(prob=0.5, type='RandomFlip'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='UDD_VDD_Dataset'),\n","    num_workers=2,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=True, type='InfiniteSampler'))\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(scale=(\n","        512,\n","        1024,\n","    ), type='Resize'),\n","    dict(prob=0.5, type='RandomFlip'),\n","    dict(type='PackSegInputs'),\n","]\n","tta_model = dict(type='SegTTAModel')\n","tta_pipeline = [\n","    dict(backend_args=None, type='LoadImageFromFile'),\n","    dict(\n","        transforms=[\n","            [\n","                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n","            ],\n","            [\n","                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n","                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n","            ],\n","            [\n","                dict(type='LoadAnnotations'),\n","            ],\n","            [\n","                dict(type='PackSegInputs'),\n","            ],\n","        ],\n","        type='TestTimeAug'),\n","]\n","val_cfg = dict(type='ValLoop')\n","val_dataloader = dict(\n","    batch_size=1,\n","    dataset=dict(\n","        data_prefix=dict(img_path='val/src', seg_map_path='val/gt'),\n","        data_root='/content/mmsegmentation/data/UDD-VDD',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(keep_ratio=True, scale=(\n","                512,\n","                1024,\n","            ), type='Resize'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='UDD_VDD_Dataset'),\n","    num_workers=4,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=False, type='DefaultSampler'))\n","val_evaluator = dict(\n","    iou_metrics=[\n","        'mIoU',\n","    ], type='IoUMetric')\n","vis_backends = [\n","    dict(type='LocalVisBackend'),\n","]\n","visualizer = dict(\n","    name='visualizer',\n","    type='SegLocalVisualizer',\n","    vis_backends=[\n","        dict(type='LocalVisBackend'),\n","    ])\n","work_dir = '/content/mmsegmentation/work_dirs/tutorial/pspnet'\n","\n"]}],"source":["from torch.utils.data import DataLoader\n","\n","\n","# Since we use only one GPU, BN is used instead of SyncBN\n","cfg.norm_cfg = dict(type='BN', requires_grad=True)\n","cfg.crop_size = (512, 1024)\n","cfg.model.data_preprocessor.size = cfg.crop_size\n","cfg.model.backbone.norm_cfg = cfg.norm_cfg\n","cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n","cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n","# modify num classes of the model in decode/auxiliary head\n","cfg.model.decode_head.num_classes = 7\n","cfg.model.auxiliary_head.num_classes = 7\n","\n","# Modify dataset type and path\n","cfg.dataset_type = 'UDD_VDD_Dataset'\n","cfg.data_root = '/content/mmsegmentation/data/UDD-VDD'\n","\n","cfg.train_dataloader.batch_size = 2\n","\n","cfg.train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(scale=(512, 1024), type='Resize'),  # Sabit boyut için Resize\n","    dict(prob=0.5, type='RandomFlip'),\n","    dict(type='PackSegInputs'),\n","\n","\n","]\n","\n","\n","cfg.test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='Resize', scale=(512, 1024), keep_ratio=True),\n","    # add loading annotation after ``Resize`` because ground truth\n","    # does not need to do resize data transform\n","    dict(type='LoadAnnotations'),\n","\n","    dict(type='PackSegInputs')\n","]\n","\n","\n","\n","cfg.train_dataloader.dataset.type = cfg.dataset_type\n","cfg.train_dataloader.dataset.data_root = cfg.data_root\n","cfg.train_dataloader.dataset.data_prefix = dict(img_path='train/src', seg_map_path='train/gt')\n","cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n","\n","\n","cfg.val_dataloader.dataset.type = cfg.dataset_type\n","cfg.val_dataloader.dataset.data_root = cfg.data_root\n","cfg.val_dataloader.dataset.data_prefix = dict(img_path='val/src', seg_map_path='val/gt')\n","cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n","\n","\n","cfg.test_dataloader = cfg.val_dataloader\n","\n","\n","# Load the pretrained weights\n","cfg.load_from = 'configs_and_weights/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n","# Set up working dir to save files and logs.\n","cfg.work_dir = 'work_dirs/tutorial/pspnet'\n","\n","cfg.train_cfg.max_iters = 10000\n","cfg.train_cfg.val_interval = 2500\n","cfg.default_hooks.logger.interval = 2500\n","cfg.default_hooks.checkpoint.interval = 2500\n","\n","# Set seed to facilitate reproducing the result\n","cfg['randomness'] = dict(seed=0)\n","\n","# Let's have a look at the final config used for training\n","print(f'Config:\\n{cfg.pretty_text}')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QWuH14LYF2gQ"},"source":["### Train\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":6767,"status":"ok","timestamp":1717006338473,"user":{"displayName":"eren coşkun","userId":"10852037997743920338"},"user_tz":-180},"id":"jYKoSfdMF12B","outputId":"d023eb86-f475-420c-a873-2ba53661e048"},"outputs":[{"name":"stdout","output_type":"stream","text":["05/29 18:12:12 - mmengine - INFO - \n","------------------------------------------------------------\n","System environment:\n","    sys.platform: linux\n","    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n","    CUDA available: True\n","    MUSA available: False\n","    numpy_random_seed: 0\n","    GPU 0: Tesla T4\n","    CUDA_HOME: /usr/local/cuda\n","    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n","    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n","    PyTorch: 1.12.0+cu102\n","    PyTorch compiling details: PyTorch built with:\n","  - GCC 7.3\n","  - C++ Version: 201402\n","  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 10.2\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n","  - CuDNN 7.6.5\n","  - Magma 2.5.2\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n","\n","    TorchVision: 0.13.0+cu102\n","    OpenCV: 4.8.0\n","    MMEngine: 0.10.4\n","\n","Runtime environment:\n","    cudnn_benchmark: True\n","    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n","    dist_cfg: {'backend': 'nccl'}\n","    seed: 0\n","    Distributed launcher: none\n","    Distributed training: False\n","    GPU number: 1\n","------------------------------------------------------------\n","\n","05/29 18:12:12 - mmengine - INFO - Config:\n","crop_size = (\n","    512,\n","    1024,\n",")\n","data_preprocessor = dict(\n","    bgr_to_rgb=True,\n","    mean=[\n","        123.675,\n","        116.28,\n","        103.53,\n","    ],\n","    pad_val=0,\n","    seg_pad_val=255,\n","    size=(\n","        512,\n","        1024,\n","    ),\n","    std=[\n","        58.395,\n","        57.12,\n","        57.375,\n","    ],\n","    type='SegDataPreProcessor')\n","data_root = '/content/mmsegmentation/data/UDD-VDD'\n","dataset_type = 'UDD_VDD_Dataset'\n","default_hooks = dict(\n","    checkpoint=dict(by_epoch=False, interval=500, type='CheckpointHook'),\n","    logger=dict(interval=500, log_metric_by_epoch=False, type='LoggerHook'),\n","    param_scheduler=dict(type='ParamSchedulerHook'),\n","    sampler_seed=dict(type='DistSamplerSeedHook'),\n","    timer=dict(type='IterTimerHook'),\n","    visualization=dict(type='SegVisualizationHook'))\n","default_scope = 'mmseg'\n","env_cfg = dict(\n","    cudnn_benchmark=True,\n","    dist_cfg=dict(backend='nccl'),\n","    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n","img_ratios = [\n","    0.5,\n","    0.75,\n","    1.0,\n","    1.25,\n","    1.5,\n","    1.75,\n","]\n","load_from = '/content/drive/MyDrive/mmsegmentation-colab/mmsegmentation/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n","log_level = 'INFO'\n","log_processor = dict(by_epoch=False)\n","model = dict(\n","    auxiliary_head=dict(\n","        align_corners=False,\n","        channels=256,\n","        concat_input=False,\n","        dropout_ratio=0.1,\n","        in_channels=1024,\n","        in_index=2,\n","        loss_decode=dict(\n","            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n","        norm_cfg=dict(requires_grad=True, type='BN'),\n","        num_classes=7,\n","        num_convs=1,\n","        type='FCNHead'),\n","    backbone=dict(\n","        contract_dilation=True,\n","        depth=50,\n","        dilations=(\n","            1,\n","            1,\n","            2,\n","            4,\n","        ),\n","        norm_cfg=dict(requires_grad=True, type='BN'),\n","        norm_eval=False,\n","        num_stages=4,\n","        out_indices=(\n","            0,\n","            1,\n","            2,\n","            3,\n","        ),\n","        strides=(\n","            1,\n","            2,\n","            1,\n","            1,\n","        ),\n","        style='pytorch',\n","        type='ResNetV1c'),\n","    data_preprocessor=dict(\n","        bgr_to_rgb=True,\n","        mean=[\n","            123.675,\n","            116.28,\n","            103.53,\n","        ],\n","        pad_val=0,\n","        seg_pad_val=255,\n","        size=(\n","            512,\n","            1024,\n","        ),\n","        std=[\n","            58.395,\n","            57.12,\n","            57.375,\n","        ],\n","        type='SegDataPreProcessor'),\n","    decode_head=dict(\n","        align_corners=False,\n","        channels=512,\n","        dropout_ratio=0.1,\n","        in_channels=2048,\n","        in_index=3,\n","        loss_decode=dict(\n","            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n","        norm_cfg=dict(requires_grad=True, type='BN'),\n","        num_classes=7,\n","        pool_scales=(\n","            1,\n","            2,\n","            3,\n","            6,\n","        ),\n","        type='PSPHead'),\n","    pretrained='open-mmlab://resnet50_v1c',\n","    test_cfg=dict(mode='whole'),\n","    train_cfg=dict(),\n","    type='EncoderDecoder')\n","norm_cfg = dict(requires_grad=True, type='BN')\n","optim_wrapper = dict(\n","    clip_grad=None,\n","    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n","    type='OptimWrapper')\n","optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n","param_scheduler = [\n","    dict(\n","        begin=0,\n","        by_epoch=False,\n","        end=40000,\n","        eta_min=0.0001,\n","        power=0.9,\n","        type='PolyLR'),\n","]\n","randomness = dict(seed=0)\n","resume = False\n","test_cfg = dict(type='TestLoop')\n","test_dataloader = dict(\n","    batch_size=1,\n","    dataset=dict(\n","        data_prefix=dict(img_path='val/src', seg_map_path='val/gt'),\n","        data_root='/content/mmsegmentation/data/UDD-VDD',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(keep_ratio=True, scale=(\n","                512,\n","                1024,\n","            ), type='Resize'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='UDD_VDD_Dataset'),\n","    num_workers=4,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=False, type='DefaultSampler'))\n","test_evaluator = dict(\n","    iou_metrics=[\n","        'mIoU',\n","    ], type='IoUMetric')\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(keep_ratio=True, scale=(\n","        512,\n","        1024,\n","    ), type='Resize'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='PackSegInputs'),\n","]\n","train_cfg = dict(max_iters=500, type='IterBasedTrainLoop', val_interval=250)\n","train_dataloader = dict(\n","    batch_size=2,\n","    dataset=dict(\n","        data_prefix=dict(img_path='train/src', seg_map_path='train/gt'),\n","        data_root='/content/mmsegmentation/data/UDD-VDD',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations'),\n","            dict(scale=(\n","                512,\n","                1024,\n","            ), type='Resize'),\n","            dict(prob=0.5, type='RandomFlip'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='UDD_VDD_Dataset'),\n","    num_workers=2,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=True, type='InfiniteSampler'))\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(scale=(\n","        512,\n","        1024,\n","    ), type='Resize'),\n","    dict(prob=0.5, type='RandomFlip'),\n","    dict(type='PackSegInputs'),\n","]\n","tta_model = dict(type='SegTTAModel')\n","tta_pipeline = [\n","    dict(backend_args=None, type='LoadImageFromFile'),\n","    dict(\n","        transforms=[\n","            [\n","                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n","                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n","            ],\n","            [\n","                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n","                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n","            ],\n","            [\n","                dict(type='LoadAnnotations'),\n","            ],\n","            [\n","                dict(type='PackSegInputs'),\n","            ],\n","        ],\n","        type='TestTimeAug'),\n","]\n","val_cfg = dict(type='ValLoop')\n","val_dataloader = dict(\n","    batch_size=1,\n","    dataset=dict(\n","        data_prefix=dict(img_path='val/src', seg_map_path='val/gt'),\n","        data_root='/content/mmsegmentation/data/UDD-VDD',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(keep_ratio=True, scale=(\n","                512,\n","                1024,\n","            ), type='Resize'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='PackSegInputs'),\n","        ],\n","        type='UDD_VDD_Dataset'),\n","    num_workers=4,\n","    persistent_workers=True,\n","    sampler=dict(shuffle=False, type='DefaultSampler'))\n","val_evaluator = dict(\n","    iou_metrics=[\n","        'mIoU',\n","    ], type='IoUMetric')\n","vis_backends = [\n","    dict(type='LocalVisBackend'),\n","]\n","visualizer = dict(\n","    name='visualizer',\n","    type='SegLocalVisualizer',\n","    vis_backends=[\n","        dict(type='LocalVisBackend'),\n","    ])\n","work_dir = '/content/mmsegmentation/work_dirs/tutorial/pspnet'\n","\n"]},{"name":"stderr","output_type":"stream","text":["/content/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n","  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n","/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["05/29 18:12:17 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n","05/29 18:12:17 - mmengine - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","before_train:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) DistSamplerSeedHook                \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_train_iter:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) IterTimerHook                      \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_val:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n"," -------------------- \n","before_val_epoch:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","before_val_iter:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) SegVisualizationHook               \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_val_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","after_val:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n"," -------------------- \n","after_train:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_test:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n"," -------------------- \n","before_test_epoch:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","before_test_iter:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_test_iter:\n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) SegVisualizationHook               \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_test_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_test:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n"," -------------------- \n","after_run:\n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n"]},{"name":"stderr","output_type":"stream","text":["/content/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n","  warnings.warn('The draw is False, it means that the '\n"]}],"source":["from mmengine.runner import Runner\n","\n","runner = Runner.from_cfg(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1455849,"status":"ok","timestamp":1717007796437,"user":{"displayName":"eren coşkun","userId":"10852037997743920338"},"user_tz":-180},"id":"6I8BAKhezHS1","outputId":"00e48418-3239-42a7-f4ce-4e5202036cac"},"outputs":[{"name":"stdout","output_type":"stream","text":["05/29 18:12:22 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.\n","05/29 18:12:23 - mmengine - INFO - load model from: open-mmlab://resnet50_v1c\n","05/29 18:12:23 - mmengine - INFO - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.openmmlab.com/pretrain/third_party/resnet50_v1c-2cccc1ad.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_v1c-2cccc1ad.pth\n"]},{"name":"stdout","output_type":"stream","text":["05/29 18:13:03 - mmengine - WARNING - The model and loaded state dict do not match exactly\n","\n","unexpected key in source state_dict: fc.weight, fc.bias\n","\n","Loads checkpoint by local backend from path: /content/drive/MyDrive/mmsegmentation-colab/mmsegmentation/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n","The model and loaded state dict do not match exactly\n","\n","size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([19, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([7, 512, 1, 1]).\n","size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([7]).\n","size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([19, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([7, 256, 1, 1]).\n","size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([7]).\n","05/29 18:13:03 - mmengine - INFO - Load checkpoint from /content/drive/MyDrive/mmsegmentation-colab/mmsegmentation/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n","05/29 18:13:03 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n","05/29 18:13:03 - mmengine - WARNING - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n","05/29 18:13:03 - mmengine - INFO - Checkpoints will be saved to /content/mmsegmentation/work_dirs/tutorial/pspnet.\n","05/29 18:21:48 - mmengine - INFO - Exp name: pspnet_r50-d8_4xb2-40k_cityscapes-512x1024_20240529_181212\n","05/29 18:21:48 - mmengine - INFO - Iter(train) [193/500]  lr: 9.9572e-03  eta: 0:13:54  time: 2.6765  data_time: 0.0065  memory: 11888  loss: 0.8470  decode.loss_ce: 0.6062  decode.acc_seg: 56.0283  aux.loss_ce: 0.2408  aux.acc_seg: 62.5209\n","05/29 18:24:54 - mmengine - INFO - per class results:\n","05/29 18:24:54 - mmengine - INFO - \n","+------------+-------+-------+\n","|   Class    |  IoU  |  Acc  |\n","+------------+-------+-------+\n","|   other    |  11.9 | 12.86 |\n","|    wall    | 29.71 | 41.11 |\n","|    road    |  32.5 | 37.25 |\n","| vegetation | 65.15 | 94.54 |\n","|  vehicle   | 30.86 | 66.79 |\n","|    roof    | 47.93 | 68.15 |\n","|   water    | 69.79 | 94.62 |\n","+------------+-------+-------+\n","05/29 18:24:54 - mmengine - INFO - Iter(val) [153/153]    aAcc: 62.4700  mIoU: 41.1200  mAcc: 59.3300  data_time: 0.0234  time: 0.2236\n","05/29 18:36:03 - mmengine - INFO - Iter(train) [500/500]  lr: 9.8888e-03  eta: 0:00:00  time: 2.6827  data_time: 0.0063  memory: 11287  loss: 0.8357  decode.loss_ce: 0.5933  decode.acc_seg: 31.3532  aux.loss_ce: 0.2424  aux.acc_seg: 24.3188\n","05/29 18:36:03 - mmengine - INFO - Saving checkpoint at 500 iterations\n","05/29 18:36:35 - mmengine - INFO - per class results:\n","05/29 18:36:35 - mmengine - INFO - \n","+------------+-------+-------+\n","|   Class    |  IoU  |  Acc  |\n","+------------+-------+-------+\n","|   other    | 30.79 | 61.66 |\n","|    wall    | 26.43 | 29.54 |\n","|    road    | 36.37 | 42.21 |\n","| vegetation | 61.78 | 90.74 |\n","|  vehicle   | 43.51 | 52.53 |\n","|    roof    | 33.51 | 40.12 |\n","|   water    | 34.57 | 36.42 |\n","+------------+-------+-------+\n","05/29 18:36:35 - mmengine - INFO - Iter(val) [153/153]    aAcc: 58.4100  mIoU: 38.1400  mAcc: 50.4600  data_time: 0.0219  time: 0.2004\n"]},{"data":{"text/plain":["EncoderDecoder(\n","  (data_preprocessor): SegDataPreProcessor()\n","  (backbone): ResNetV1c(\n","    (stem): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (8): ReLU(inplace=True)\n","    )\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): ResLayer(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): ResLayer(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): ResLayer(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): ResLayer(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  init_cfg={'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnet50_v1c'}\n","  (decode_head): PSPHead(\n","    input_transform=None, ignore_index=255, align_corners=False\n","    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n","    (conv_seg): Conv2d(512, 7, kernel_size=(1, 1), stride=(1, 1))\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (psp_modules): PPM(\n","      (0): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=1)\n","        (1): ConvModule(\n","          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activate): ReLU(inplace=True)\n","        )\n","      )\n","      (1): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=2)\n","        (1): ConvModule(\n","          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activate): ReLU(inplace=True)\n","        )\n","      )\n","      (2): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=3)\n","        (1): ConvModule(\n","          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activate): ReLU(inplace=True)\n","        )\n","      )\n","      (3): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=6)\n","        (1): ConvModule(\n","          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activate): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (bottleneck): ConvModule(\n","      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","  )\n","  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n","  (auxiliary_head): FCNHead(\n","    input_transform=None, ignore_index=255, align_corners=False\n","    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n","    (conv_seg): Conv2d(256, 7, kernel_size=(1, 1), stride=(1, 1))\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (convs): Sequential(\n","      (0): ConvModule(\n","        (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# start training\n","runner.train()"]},{"cell_type":"markdown","metadata":{"id":"Fb9OWD_hzHS1"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"vscode":{"interpreter":{"hash":"0442e67aee3d9cbb788fa6e86d60c4ffa94ad7f1943c65abfecb99a6f4696c58"}}},"nbformat":4,"nbformat_minor":0}
